---
layout: post
author: Shane Skiles
title: AI Context Collapse
tags: [ai, analysis, paper]
---

AI Context Collapse

<i>This will be our starting point for this post. I’m not sure where it will go, 
but it’s starting here.</i>

I know I'm a little late to the show in saying "AI is here!" but yet, here we are. 

I always thought AI would stay in more of a machine learning and data science niche, 
something bubbling up search recommendations or quietly optimizing the minutiae of 
rocket science. But instead, it has slowly worked its way into our lives. 
It has gone from being a passer-by offering advice in the background of some movie 
to a recurring character in our daily lives and conversations.

No longer just a voice in the background or a hidden algorithm, AI is now actively
participating. We talk *to* it, ask it questions, have it draft emails, brainstorm ideas,
and even generate images and sounds based on our prompts. It's moved from being
a tool we occasionally interact with, a passive utility, to an active presence.

It’s in classrooms, in courtrooms, in our pockets, and on our screens. 
It has become a collaborator, a co-creator, and in many cases, a filter 
through which we experience the world. 

When the internet started gaining popularity in the 1990's it helped facilitate
communications between individuals, whether colleagues, family or strangers.
This ability to collaborate, exchange ideas, engage in virtual communities revolutionized
the way the connected, learned and worked.

This led to what we now call "context collapse" — a blurring or breakdown of the lines 
differentiating social contexts. This lead to conversations, audiences and expectations from 
one context inappropriately crossing into another, often with unintended consequences.

AI is doing something different, and perhaps more unsettling. While the internet amplified
human voices, AI is creating its *own* voices, its *own* content, often indistinguishable
from human output. It's not just that it's hard to tell who or what is speaking. 
It's that the *nature* of information, creativity, and even conversation is changing.

What we’re seeing now isn’t collapsing the context and content it’s a reshaping 
of context and content itself. The lines between original and generated, 
real and synthetic are blurring fast.

What are the consequences of blurring the lines between people and AI?

And it’s not just that AI can generate content and can do so in ways that 
absorb and remix vast amounts of human-created material — it works the 
other way also. People are integrating AI into their own creative 
processes, using it to conceive, generate and refine their own works.

We’re losing the metadata that used to help us understand
the *why*, *how*, and *who* behind the things we experience.

Do we need re-learn and re-teach media literacy from the ground up?
Change how we consume and trust information online, shifting to
verified sources, trusted networks, new forms of digital literacy?

Do we need new tools, new forms of digital literacy to understand the origins
and intentions of the content? Or do we fundamentally have to accept that the 
lines between human and machine have blurred and this is the new normal?

I'm not sure where this will go, but here we are.


